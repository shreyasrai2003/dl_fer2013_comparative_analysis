{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-17T04:54:23.237648Z",
     "start_time": "2023-10-17T04:54:16.479995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31m_RemoteTraceback\u001B[0m                          Traceback (most recent call last)",
      "\u001B[0;31m_RemoteTraceback\u001B[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/joblib/externals/loky/backend/queues.py\", line 159, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/joblib/externals/loky/backend/reduction.py\", line 215, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/joblib/externals/loky/backend/reduction.py\", line 208, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/joblib/externals/cloudpickle/cloudpickle_fast.py\", line 632, in dump\n    return Pickler.dump(self, obj)\n           ^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: cannot pickle 'LazyLoader' object\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mPicklingError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 92\u001B[0m\n\u001B[1;32m     83\u001B[0m random_search \u001B[38;5;241m=\u001B[39m RandomizedSearchCV(\n\u001B[1;32m     84\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m     85\u001B[0m     param_distributions\u001B[38;5;241m=\u001B[39mparam_dist,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     88\u001B[0m     n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m  \u001B[38;5;66;03m# Use all available CPU cores for parallelism\u001B[39;00m\n\u001B[1;32m     89\u001B[0m )\n\u001B[1;32m     91\u001B[0m \u001B[38;5;66;03m# Perform the Randomized Search\u001B[39;00m\n\u001B[0;32m---> 92\u001B[0m \u001B[43mrandom_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;66;03m# Get the best parameters and their accuracy\u001B[39;00m\n\u001B[1;32m     95\u001B[0m best_params \u001B[38;5;241m=\u001B[39m random_search\u001B[38;5;241m.\u001B[39mbest_params_\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/sklearn/base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1150\u001B[0m     )\n\u001B[1;32m   1151\u001B[0m ):\n\u001B[0;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    892\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    893\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    894\u001B[0m     )\n\u001B[1;32m    896\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 898\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    901\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    902\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1809\u001B[0m, in \u001B[0;36mRandomizedSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1807\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1808\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1809\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1810\u001B[0m \u001B[43m        \u001B[49m\u001B[43mParameterSampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1811\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_distributions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\n\u001B[1;32m   1812\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1813\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    837\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    838\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    839\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    840\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    841\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    842\u001B[0m         )\n\u001B[1;32m    843\u001B[0m     )\n\u001B[0;32m--> 845\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    846\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    847\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    848\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    849\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    850\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    851\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    853\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    854\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    856\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    857\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    858\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    859\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    860\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    862\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    863\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    864\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    865\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    866\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    867\u001B[0m     )\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     60\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     61\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     62\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     64\u001B[0m )\n\u001B[0;32m---> 65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/joblib/parallel.py:1952\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1946\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[1;32m   1947\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[1;32m   1948\u001B[0m \u001B[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001B[39;00m\n\u001B[1;32m   1949\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[1;32m   1950\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 1952\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/joblib/parallel.py:1595\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[0;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[1;32m   1592\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[1;32m   1594\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1595\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[1;32m   1597\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[1;32m   1598\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[1;32m   1599\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[1;32m   1600\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[1;32m   1601\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/joblib/parallel.py:1699\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1692\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_retrieval():\n\u001B[1;32m   1693\u001B[0m \n\u001B[1;32m   1694\u001B[0m     \u001B[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001B[39;00m\n\u001B[1;32m   1695\u001B[0m     \u001B[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001B[39;00m\n\u001B[1;32m   1696\u001B[0m     \u001B[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001B[39;00m\n\u001B[1;32m   1697\u001B[0m     \u001B[38;5;66;03m# worker traceback.\u001B[39;00m\n\u001B[1;32m   1698\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aborting:\n\u001B[0;32m-> 1699\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_error_fast\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1700\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m   1702\u001B[0m     \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[1;32m   1703\u001B[0m     \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/joblib/parallel.py:1734\u001B[0m, in \u001B[0;36mParallel._raise_error_fast\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1730\u001B[0m \u001B[38;5;66;03m# If this error job exists, immediatly raise the error by\u001B[39;00m\n\u001B[1;32m   1731\u001B[0m \u001B[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001B[39;00m\n\u001B[1;32m   1732\u001B[0m \u001B[38;5;66;03m# called directly or if the generator is gc'ed.\u001B[39;00m\n\u001B[1;32m   1733\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m error_job \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1734\u001B[0m     \u001B[43merror_job\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_result\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/joblib/parallel.py:736\u001B[0m, in \u001B[0;36mBatchCompletionCallBack.get_result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    730\u001B[0m backend \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparallel\u001B[38;5;241m.\u001B[39m_backend\n\u001B[1;32m    732\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend\u001B[38;5;241m.\u001B[39msupports_retrieve_callback:\n\u001B[1;32m    733\u001B[0m     \u001B[38;5;66;03m# We assume that the result has already been retrieved by the\u001B[39;00m\n\u001B[1;32m    734\u001B[0m     \u001B[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001B[39;00m\n\u001B[1;32m    735\u001B[0m     \u001B[38;5;66;03m# be returned.\u001B[39;00m\n\u001B[0;32m--> 736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_return_or_raise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    738\u001B[0m \u001B[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001B[39;00m\n\u001B[1;32m    739\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/joblib/parallel.py:754\u001B[0m, in \u001B[0;36mBatchCompletionCallBack._return_or_raise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    752\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    753\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m TASK_ERROR:\n\u001B[0;32m--> 754\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n\u001B[1;32m    755\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n\u001B[1;32m    756\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "\u001B[0;31mPicklingError\u001B[0m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "# Set your data directory\n",
    "data_directory = '/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/data/train'  # Update this path to the directory containing your dataset\n",
    "\n",
    "# Define constants\n",
    "input_shape = (48, 48, 1)  # Updated input size to match your image size\n",
    "num_classes = 7  # Automatically determine the number of classes\n",
    "batch_size = 8192\n",
    "\n",
    "# Data preprocessing and augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,  # Normalize pixel values to the [0, 1] range\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load and preprocess the data\n",
    "datagen_with_preprocessing = datagen.flow_from_directory(\n",
    "    data_directory,\n",
    "    target_size=(48, 48),  # Updated target size\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X, y = datagen_with_preprocessing.next()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert y_train to one-hot encoding\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "# Function to create the model\n",
    "def create_model(optimizer='adam', loss='categorical_crossentropy', dropout_rate=0.2):\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Wrap the Keras model as a scikit-learn estimator\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Define hyperparameter options\n",
    "param_dist = {\n",
    "    'optimizer': ['adam', 'rmsprop', 'sgd', 'adagrad'],\n",
    "    'loss': ['categorical_crossentropy', 'kullback_leibler_divergence', 'squared_hinge', 'huber_loss'],\n",
    "    'batch_size': [8192, 16384],\n",
    "    'epochs': [20, 50, 100]\n",
    "}\n",
    "\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "# Perform the Randomized Search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  # Number of random parameter combinations to try\n",
    "    cv=k_fold,  # Use MultiLabelKFold for multilabel data\n",
    "    n_jobs=-1  # Use all available CPU cores for parallelism\n",
    ")\n",
    "\n",
    "# Perform the Randomized Search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and their accuracy\n",
    "best_params = random_search.best_params_\n",
    "best_accuracy = random_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy: {:.2f}%\".format(best_accuracy * 100))\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Total training time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "185/185 [==============================] - 7s 34ms/step - loss: 1.8223 - accuracy: 0.2418\n",
      "21/21 [==============================] - 0s 12ms/step\n",
      "185/185 [==============================] - 8s 35ms/step - loss: 1.8150 - accuracy: 0.2435\n",
      "21/21 [==============================] - 0s 9ms/step\n",
      "185/185 [==============================] - 11s 57ms/step - loss: 1.8292 - accuracy: 0.2391\n",
      "185/185 [==============================] - 12s 58ms/step - loss: 1.8347 - accuracy: 0.2406\n",
      "21/21 [==============================] - 0s 18ms/step\n",
      "185/185 [==============================] - 12s 56ms/step - loss: 1.8324 - accuracy: 0.2358\n",
      "21/21 [==============================] - 0s 13ms/step\n",
      "185/185 [==============================] - 12s 60ms/step - loss: 1.8242 - accuracy: 0.2428\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "185/185 [==============================] - 12s 61ms/step - loss: 1.8215 - accuracy: 0.2410\n",
      "21/21 [==============================] - 0s 13ms/step\n",
      "185/185 [==============================] - 13s 62ms/step - loss: 1.8309 - accuracy: 0.2418\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "21/21 [==============================] - 0s 9ms/step\n",
      "185/185 [==============================] - 7s 36ms/step - loss: 1.8273 - accuracy: 0.2418\n",
      "21/21 [==============================] - 0s 8ms/step\n",
      "185/185 [==============================] - 7s 37ms/step - loss: 1.8285 - accuracy: 0.2416\n",
      "21/21 [==============================] - 0s 7ms/step\n",
      "185/185 [==============================] - 6s 30ms/step - loss: 1.8250 - accuracy: 0.2409\n",
      "21/21 [==============================] - 0s 8ms/step\n",
      "185/185 [==============================] - 7s 33ms/step - loss: 1.8227 - accuracy: 0.2450\n",
      "21/21 [==============================] - 0s 9ms/step\n",
      "185/185 [==============================] - 11s 54ms/step - loss: 1.8247 - accuracy: 0.2406\n",
      "185/185 [==============================] - 11s 54ms/step - loss: 1.8245 - accuracy: 0.2428\n",
      "21/21 [==============================] - 0s 12ms/step\n",
      "21/21 [==============================] - 0s 15ms/step\n",
      "185/185 [==============================] - 11s 57ms/step - loss: 1.8261 - accuracy: 0.2442\n",
      "185/185 [==============================] - 11s 59ms/step - loss: 1.8294 - accuracy: 0.2423\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "185/185 [==============================] - 11s 59ms/step - loss: 1.8192 - accuracy: 0.2348\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "21/21 [==============================] - 0s 10ms/step\n",
      "185/185 [==============================] - 12s 60ms/step - loss: 1.8261 - accuracy: 0.2448\n",
      "21/21 [==============================] - 0s 9ms/step\n",
      "185/185 [==============================] - 7s 34ms/step - loss: 1.8293 - accuracy: 0.2401\n",
      "21/21 [==============================] - 0s 7ms/step\n",
      "185/185 [==============================] - 7s 36ms/step - loss: 1.8192 - accuracy: 0.2419\n",
      "21/21 [==============================] - 0s 8ms/step\n",
      "185/185 [==============================] - 6s 30ms/step - loss: 1.8245 - accuracy: 0.2448\n",
      "21/21 [==============================] - 0s 7ms/step\n",
      "185/185 [==============================] - 11s 57ms/step - loss: 1.8228 - accuracy: 0.2411\n",
      "185/185 [==============================] - 11s 57ms/step - loss: 1.8202 - accuracy: 0.2408\n",
      "185/185 [==============================] - 11s 58ms/step - loss: 1.8282 - accuracy: 0.2389\n",
      "21/21 [==============================] - 0s 12ms/step\n",
      "21/21 [==============================] - 0s 13ms/step\n",
      "185/185 [==============================] - 7s 33ms/step - loss: 1.8263 - accuracy: 0.2399\n",
      "185/185 [==============================] - 12s 60ms/step - loss: 1.8286 - accuracy: 0.2449\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "185/185 [==============================] - 12s 61ms/step - loss: 1.8240 - accuracy: 0.2425\n",
      "21/21 [==============================] - 0s 8ms/step\n",
      "21/21 [==============================] - 0s 8ms/step\n",
      "21/21 [==============================] - 0s 7ms/step\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 1.8248 - accuracy: 0.2445\n",
      "21/21 [==============================] - 0s 6ms/step\n",
      "185/185 [==============================] - 5s 22ms/step - loss: 1.8267 - accuracy: 0.2375\n",
      "21/21 [==============================] - 0s 5ms/step\n",
      "185/185 [==============================] - 4s 19ms/step - loss: 1.8236 - accuracy: 0.2486\n",
      "21/21 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "70 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/scikeras/wrappers.py\", line 1491, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/scikeras/wrappers.py\", line 760, in fit\n",
      "    self._fit(\n",
      "  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/scikeras/wrappers.py\", line 926, in _fit\n",
      "    self._check_model_compatibility(y)\n",
      "  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/scikeras/wrappers.py\", line 569, in _check_model_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: loss=kullback_leibler_divergence but model compiled with categorical_crossentropy. Data may not match loss function!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/scikeras/wrappers.py\", line 1491, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/scikeras/wrappers.py\", line 760, in fit\n",
      "    self._fit(\n",
      "  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/scikeras/wrappers.py\", line 926, in _fit\n",
      "    self._check_model_compatibility(y)\n",
      "  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/scikeras/wrappers.py\", line 569, in _check_model_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: loss=squared_hinge but model compiled with categorical_crossentropy. Data may not match loss function!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/scikeras/wrappers.py\", line 1491, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/scikeras/wrappers.py\", line 760, in fit\n",
      "    self._fit(\n",
      "  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/scikeras/wrappers.py\", line 926, in _fit\n",
      "    self._check_model_compatibility(y)\n",
      "  File \"/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/scikeras/wrappers.py\", line 569, in _check_model_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: loss=huber_loss but model compiled with categorical_crossentropy. Data may not match loss function!\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.25103007        nan        nan 0.24843581        nan        nan\n",
      "        nan        nan        nan 0.24599283]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 4s 18ms/step - loss: 1.8177 - accuracy: 0.2431\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomizedSearchCV(cv=10,\n                   estimator=KerasClassifier(model=<function create_model at 0x2c312a520>),\n                   n_jobs=-1,\n                   param_distributions={'loss': ['categorical_crossentropy',\n                                                 'kullback_leibler_divergence',\n                                                 'squared_hinge',\n                                                 'huber_loss'],\n                                        'optimizer': ['adam', 'rmsprop',\n                                                      'sgd']})",
      "text/html": "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10,\n                   estimator=KerasClassifier(model=&lt;function create_model at 0x2c312a520&gt;),\n                   n_jobs=-1,\n                   param_distributions={&#x27;loss&#x27;: [&#x27;categorical_crossentropy&#x27;,\n                                                 &#x27;kullback_leibler_divergence&#x27;,\n                                                 &#x27;squared_hinge&#x27;,\n                                                 &#x27;huber_loss&#x27;],\n                                        &#x27;optimizer&#x27;: [&#x27;adam&#x27;, &#x27;rmsprop&#x27;,\n                                                      &#x27;sgd&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10,\n                   estimator=KerasClassifier(model=&lt;function create_model at 0x2c312a520&gt;),\n                   n_jobs=-1,\n                   param_distributions={&#x27;loss&#x27;: [&#x27;categorical_crossentropy&#x27;,\n                                                 &#x27;kullback_leibler_divergence&#x27;,\n                                                 &#x27;squared_hinge&#x27;,\n                                                 &#x27;huber_loss&#x27;],\n                                        &#x27;optimizer&#x27;: [&#x27;adam&#x27;, &#x27;rmsprop&#x27;,\n                                                      &#x27;sgd&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n\tmodel=&lt;function create_model at 0x2c312a520&gt;\n\tbuild_fn=None\n\twarm_start=False\n\trandom_state=None\n\toptimizer=rmsprop\n\tloss=None\n\tmetrics=None\n\tbatch_size=None\n\tvalidation_batch_size=None\n\tverbose=1\n\tcallbacks=None\n\tvalidation_split=0.0\n\tshuffle=True\n\trun_eagerly=False\n\tepochs=1\n\tclass_weight=None\n)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n\tmodel=&lt;function create_model at 0x2c312a520&gt;\n\tbuild_fn=None\n\twarm_start=False\n\trandom_state=None\n\toptimizer=rmsprop\n\tloss=None\n\tmetrics=None\n\tbatch_size=None\n\tvalidation_batch_size=None\n\tverbose=1\n\tcallbacks=None\n\tvalidation_split=0.0\n\tshuffle=True\n\trun_eagerly=False\n\tepochs=1\n\tclass_weight=None\n)</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T11:13:18.073865Z",
     "start_time": "2023-10-14T11:12:28.555616Z"
    }
   },
   "id": "210218c2a3399d1e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-17T03:05:48.490521Z",
     "start_time": "2023-10-17T03:05:48.487821Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from functools import partial\n",
    "\n",
    "# Plot training and validation metrics\n",
    "def plot_training_history(history):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(history.history['categorical_accuracy'])\n",
    "    plt.plot(history.history['val_categorical_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(122)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n",
      "Epoch 1/50\n",
      "448/448 [==============================] - 13s 27ms/step - loss: 1.7934 - accuracy: 0.2652 - val_loss: 1.6810 - val_accuracy: 0.3499\n",
      "Epoch 2/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 1.6045 - accuracy: 0.3781 - val_loss: 1.5168 - val_accuracy: 0.4240\n",
      "Epoch 3/50\n",
      "448/448 [==============================] - 11s 26ms/step - loss: 1.4952 - accuracy: 0.4276 - val_loss: 1.4369 - val_accuracy: 0.4488\n",
      "Epoch 4/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 1.4245 - accuracy: 0.4585 - val_loss: 1.3820 - val_accuracy: 0.4707\n",
      "Epoch 5/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 1.3684 - accuracy: 0.4814 - val_loss: 1.3382 - val_accuracy: 0.4920\n",
      "Epoch 6/50\n",
      "448/448 [==============================] - 11s 26ms/step - loss: 1.3267 - accuracy: 0.4980 - val_loss: 1.3054 - val_accuracy: 0.5025\n",
      "Epoch 7/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 1.2928 - accuracy: 0.5136 - val_loss: 1.2771 - val_accuracy: 0.5130\n",
      "Epoch 8/50\n",
      "448/448 [==============================] - 11s 26ms/step - loss: 1.2650 - accuracy: 0.5213 - val_loss: 1.2819 - val_accuracy: 0.5159\n",
      "Epoch 9/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 1.2439 - accuracy: 0.5331 - val_loss: 1.3093 - val_accuracy: 0.5112\n",
      "Epoch 10/50\n",
      "448/448 [==============================] - 11s 26ms/step - loss: 1.2203 - accuracy: 0.5435 - val_loss: 1.2365 - val_accuracy: 0.5321\n",
      "Epoch 11/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 1.2070 - accuracy: 0.5489 - val_loss: 1.2230 - val_accuracy: 0.5347\n",
      "Epoch 12/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 1.2030 - accuracy: 0.5507 - val_loss: 1.2247 - val_accuracy: 0.5403\n",
      "Epoch 13/50\n",
      "448/448 [==============================] - 11s 25ms/step - loss: 1.2023 - accuracy: 0.5521 - val_loss: 1.2189 - val_accuracy: 0.5435\n",
      "Epoch 14/50\n",
      "448/448 [==============================] - 11s 25ms/step - loss: 1.2110 - accuracy: 0.5521 - val_loss: 1.2577 - val_accuracy: 0.5416\n",
      "Epoch 15/50\n",
      "448/448 [==============================] - 11s 26ms/step - loss: 1.2560 - accuracy: 0.5504 - val_loss: 1.2891 - val_accuracy: 0.5321\n",
      "Epoch 16/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 1.3113 - accuracy: 0.5428 - val_loss: 1.3117 - val_accuracy: 0.5382\n",
      "Epoch 17/50\n",
      "448/448 [==============================] - 11s 25ms/step - loss: 1.4403 - accuracy: 0.5258 - val_loss: 1.5049 - val_accuracy: 0.5218\n",
      "Epoch 18/50\n",
      "448/448 [==============================] - 11s 26ms/step - loss: 1.5837 - accuracy: 0.5173 - val_loss: 1.5524 - val_accuracy: 0.5068\n",
      "Epoch 19/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 1.8716 - accuracy: 0.5002 - val_loss: 2.0567 - val_accuracy: 0.4826\n",
      "Epoch 20/50\n",
      "448/448 [==============================] - 11s 26ms/step - loss: 2.3673 - accuracy: 0.4787 - val_loss: 2.0726 - val_accuracy: 0.5165\n",
      "Epoch 21/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 2.9205 - accuracy: 0.4695 - val_loss: 3.2830 - val_accuracy: 0.4714\n",
      "Epoch 22/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 3.7009 - accuracy: 0.4572 - val_loss: 3.5215 - val_accuracy: 0.4646\n",
      "Epoch 23/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 4.8929 - accuracy: 0.4445 - val_loss: 5.8993 - val_accuracy: 0.4029\n",
      "Epoch 24/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 6.7963 - accuracy: 0.4300 - val_loss: 8.9676 - val_accuracy: 0.3740\n",
      "Epoch 25/50\n",
      "448/448 [==============================] - 11s 26ms/step - loss: 8.8940 - accuracy: 0.4215 - val_loss: 10.0414 - val_accuracy: 0.4195\n",
      "Epoch 26/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 12.1371 - accuracy: 0.4117 - val_loss: 18.3408 - val_accuracy: 0.3227\n",
      "Epoch 27/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 16.9947 - accuracy: 0.4029 - val_loss: 23.1424 - val_accuracy: 0.3465\n",
      "Epoch 28/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 21.9388 - accuracy: 0.3960 - val_loss: 30.1429 - val_accuracy: 0.3309\n",
      "Epoch 29/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 30.0171 - accuracy: 0.3887 - val_loss: 38.6964 - val_accuracy: 0.3698\n",
      "Epoch 30/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 38.3820 - accuracy: 0.3837 - val_loss: 49.0486 - val_accuracy: 0.3661\n",
      "Epoch 31/50\n",
      "448/448 [==============================] - 11s 26ms/step - loss: 50.3145 - accuracy: 0.3802 - val_loss: 67.5319 - val_accuracy: 0.3041\n",
      "Epoch 32/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 62.8568 - accuracy: 0.3761 - val_loss: 103.8198 - val_accuracy: 0.3015\n",
      "Epoch 33/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 84.0171 - accuracy: 0.3659 - val_loss: 169.7261 - val_accuracy: 0.2465\n",
      "Epoch 34/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 105.6885 - accuracy: 0.3665 - val_loss: 132.7494 - val_accuracy: 0.3387\n",
      "Epoch 35/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 134.8947 - accuracy: 0.3604 - val_loss: 156.7863 - val_accuracy: 0.3118\n",
      "Epoch 36/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 161.6555 - accuracy: 0.3611 - val_loss: 290.6634 - val_accuracy: 0.2663\n",
      "Epoch 37/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 203.4173 - accuracy: 0.3513 - val_loss: 345.8979 - val_accuracy: 0.2559\n",
      "Epoch 38/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 259.3899 - accuracy: 0.3466 - val_loss: 406.4936 - val_accuracy: 0.2962\n",
      "Epoch 39/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 313.2271 - accuracy: 0.3476 - val_loss: 593.9565 - val_accuracy: 0.2540\n",
      "Epoch 40/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 386.0870 - accuracy: 0.3426 - val_loss: 537.9755 - val_accuracy: 0.2591\n",
      "Epoch 41/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 476.6098 - accuracy: 0.3393 - val_loss: 684.9236 - val_accuracy: 0.2494\n",
      "Epoch 42/50\n",
      "448/448 [==============================] - 11s 26ms/step - loss: 548.8347 - accuracy: 0.3420 - val_loss: 783.6102 - val_accuracy: 0.2787\n",
      "Epoch 43/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 673.2803 - accuracy: 0.3391 - val_loss: 1087.2673 - val_accuracy: 0.2842\n",
      "Epoch 44/50\n",
      "448/448 [==============================] - 11s 25ms/step - loss: 780.1063 - accuracy: 0.3307 - val_loss: 871.6680 - val_accuracy: 0.3090\n",
      "Epoch 45/50\n",
      "448/448 [==============================] - 11s 25ms/step - loss: 922.0145 - accuracy: 0.3269 - val_loss: 1396.7029 - val_accuracy: 0.2644\n",
      "Epoch 46/50\n",
      "448/448 [==============================] - 11s 26ms/step - loss: 1030.6611 - accuracy: 0.3288 - val_loss: 1878.0818 - val_accuracy: 0.2718\n",
      "Epoch 47/50\n",
      "448/448 [==============================] - 11s 26ms/step - loss: 1202.1245 - accuracy: 0.3303 - val_loss: 1367.3698 - val_accuracy: 0.2907\n",
      "Epoch 48/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 1405.3156 - accuracy: 0.3240 - val_loss: 2193.9910 - val_accuracy: 0.2554\n",
      "Epoch 49/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 1607.4290 - accuracy: 0.3243 - val_loss: 2182.5308 - val_accuracy: 0.2856\n",
      "Epoch 50/50\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 1817.9618 - accuracy: 0.3247 - val_loss: 2338.8291 - val_accuracy: 0.2906\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#preprocessing training and validation data\n",
    "train_dir = '/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/data/train'\n",
    "val_dir = '/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/data/test'\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)  #scales the pixel value from [0,255] to [0,1]\n",
    "\n",
    "\n",
    "#generator objects for both training and validation sets are created using the 'flow_from_directory' method\n",
    "#yields batches of augmented and preprocessed images with labels\n",
    "train_generator = train_datagen.flow_from_directory(      #preprocess taining data\n",
    "        train_dir,\n",
    "        target_size=(48,48),      #target_size parameter specifies the size to which the images should be resized\n",
    "        batch_size=64,            #batch_size is the size of the batches that will be yielded by the generator\n",
    "        color_mode=\"grayscale\",   # color_mode specifies the number of color channels\n",
    "        class_mode='categorical') #class_mode specifies the type of labels\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(     #preprocess validation data\n",
    "        val_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "emotion_model = Sequential()   #The model is created using the Sequential model class from Keras. \n",
    "                               #This allows us to add layers to the model in a sequential order.\n",
    "\n",
    "\n",
    "#input_shape parameter specifies the shape of the input data.\n",
    "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1))) #kernel_size parameter specifies the size of the filters\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))  #activation specifies the activation function to be used\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "#MaxPooling2D layer downsamples the feature maps produced by the convolutional layer by taking the maximum value in each pooling window\n",
    "#The pool_size parameter specifies the size of the pooling window.\n",
    "\n",
    "emotion_model.add(Dropout(0.25))\n",
    "#Two dropout layers (Dropout) are added after the first and last pooling layers. \n",
    "# This layer randomly drops out a certain percentage of the neurons in the layer during training to prevent overfitting.\n",
    "\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "# flattened output is passed through two fully connected (Dense) layers.\n",
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024, activation='relu'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# The loss parameter specifies the loss function to be used, which is categorical cross-entropy in this case.\n",
    "emotion_model.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=0.0001, decay=1e-6),metrics=['accuracy'])\n",
    "#The metrics parameter specifies the metric to be used to evaluate the performance of the model during training, which is accuracy in this case.\n",
    "\n",
    "emotion_model_info = emotion_model.fit(\n",
    "        #The train_generator and validation_generator are passed as inputs to this method\n",
    "        train_generator, \n",
    "        #The steps_per_epoch and validation_steps parameters specify the number of batches to be yielded by the generators in one epoch.\n",
    "        steps_per_epoch=28709 // 64,\n",
    "        epochs=50, \n",
    "        validation_data=validation_generator,  \n",
    "        validation_steps=7178 // 64)\n",
    "\n",
    "emotion_model.save('model.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T02:36:48.713367Z",
     "start_time": "2023-10-17T02:27:11.591223Z"
    }
   },
   "id": "62c128bebdfa0af7"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 3.1788 - categorical_accuracy: 0.1176 - val_loss: 1.9824 - val_categorical_accuracy: 0.0769\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.2629 - categorical_accuracy: 0.1765 - val_loss: 1.9776 - val_categorical_accuracy: 0.0769\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.9725 - categorical_accuracy: 0.1961 - val_loss: 1.9729 - val_categorical_accuracy: 0.0769\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.2684 - categorical_accuracy: 0.2157 - val_loss: 1.9684 - val_categorical_accuracy: 0.0769\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.2106 - categorical_accuracy: 0.2353 - val_loss: 1.9641 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.2789 - categorical_accuracy: 0.2157 - val_loss: 1.9600 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.0797 - categorical_accuracy: 0.2157 - val_loss: 1.9561 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0022 - categorical_accuracy: 0.1961 - val_loss: 1.9523 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0844 - categorical_accuracy: 0.1569 - val_loss: 1.9487 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.3816 - categorical_accuracy: 0.1176 - val_loss: 1.9456 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.8983 - categorical_accuracy: 0.2157 - val_loss: 1.9429 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0890 - categorical_accuracy: 0.1569 - val_loss: 1.9404 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.2061 - categorical_accuracy: 0.1765 - val_loss: 1.9381 - val_categorical_accuracy: 0.0769\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.1216 - categorical_accuracy: 0.2157 - val_loss: 1.9359 - val_categorical_accuracy: 0.1538\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.3053 - categorical_accuracy: 0.1373 - val_loss: 1.9335 - val_categorical_accuracy: 0.2308\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 3.2402 - categorical_accuracy: 0.1765 - val_loss: 1.9313 - val_categorical_accuracy: 0.2308\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.1184 - categorical_accuracy: 0.1569 - val_loss: 1.9296 - val_categorical_accuracy: 0.2308\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.2445 - categorical_accuracy: 0.1569 - val_loss: 1.9283 - val_categorical_accuracy: 0.2308\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.2060 - categorical_accuracy: 0.1961 - val_loss: 1.9270 - val_categorical_accuracy: 0.2308\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1376 - categorical_accuracy: 0.1373 - val_loss: 1.9255 - val_categorical_accuracy: 0.2308\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.5198 - categorical_accuracy: 0.1569 - val_loss: 1.9244 - val_categorical_accuracy: 0.2308\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.3563 - categorical_accuracy: 0.1961 - val_loss: 1.9236 - val_categorical_accuracy: 0.2308\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.2483 - categorical_accuracy: 0.1569 - val_loss: 1.9228 - val_categorical_accuracy: 0.2308\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0273 - categorical_accuracy: 0.1373 - val_loss: 1.9222 - val_categorical_accuracy: 0.2308\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.1376 - categorical_accuracy: 0.1569 - val_loss: 1.9218 - val_categorical_accuracy: 0.2308\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1267 - categorical_accuracy: 0.1765 - val_loss: 1.9214 - val_categorical_accuracy: 0.2308\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.1409 - categorical_accuracy: 0.2157 - val_loss: 1.9213 - val_categorical_accuracy: 0.2308\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.1417 - categorical_accuracy: 0.1961 - val_loss: 1.9213 - val_categorical_accuracy: 0.2308\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.2700 - categorical_accuracy: 0.2353 - val_loss: 1.9214 - val_categorical_accuracy: 0.2308\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.1401 - categorical_accuracy: 0.1765 - val_loss: 1.9215 - val_categorical_accuracy: 0.2308\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.9520 - categorical_accuracy: 0.1765 - val_loss: 1.9217 - val_categorical_accuracy: 0.2308\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.1483 - categorical_accuracy: 0.1961 - val_loss: 1.9220 - val_categorical_accuracy: 0.2308\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.4246 - categorical_accuracy: 0.1569 - val_loss: 1.9225 - val_categorical_accuracy: 0.2308\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.3340 - categorical_accuracy: 0.1765 - val_loss: 1.9229 - val_categorical_accuracy: 0.2308\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.3515 - categorical_accuracy: 0.1765 - val_loss: 1.9234 - val_categorical_accuracy: 0.2308\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.9591 - categorical_accuracy: 0.1961 - val_loss: 1.9237 - val_categorical_accuracy: 0.2308\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.2867 - categorical_accuracy: 0.1765 - val_loss: 1.9240 - val_categorical_accuracy: 0.2308\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.2149 - categorical_accuracy: 0.1961 - val_loss: 1.9243 - val_categorical_accuracy: 0.2308\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1897 - categorical_accuracy: 0.1373 - val_loss: 1.9246 - val_categorical_accuracy: 0.2308\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.0457 - categorical_accuracy: 0.1765 - val_loss: 1.9249 - val_categorical_accuracy: 0.2308\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1158 - categorical_accuracy: 0.1765 - val_loss: 1.9252 - val_categorical_accuracy: 0.2308\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.3050 - categorical_accuracy: 0.1569 - val_loss: 1.9255 - val_categorical_accuracy: 0.2308\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0881 - categorical_accuracy: 0.1765 - val_loss: 1.9258 - val_categorical_accuracy: 0.2308\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.3253 - categorical_accuracy: 0.1569 - val_loss: 1.9260 - val_categorical_accuracy: 0.2308\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.1847 - categorical_accuracy: 0.1569 - val_loss: 1.9263 - val_categorical_accuracy: 0.2308\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0770 - categorical_accuracy: 0.2157 - val_loss: 1.9266 - val_categorical_accuracy: 0.2308\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.2747 - categorical_accuracy: 0.1373 - val_loss: 1.9269 - val_categorical_accuracy: 0.2308\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.1705 - categorical_accuracy: 0.1569 - val_loss: 1.9272 - val_categorical_accuracy: 0.2308\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.2523 - categorical_accuracy: 0.1373 - val_loss: 1.9275 - val_categorical_accuracy: 0.2308\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.1253 - categorical_accuracy: 0.1569 - val_loss: 1.9278 - val_categorical_accuracy: 0.2308\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.7938 - categorical_accuracy: 0.1961 - val_loss: 1.9281 - val_categorical_accuracy: 0.2308\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.1081 - categorical_accuracy: 0.1765 - val_loss: 1.9284 - val_categorical_accuracy: 0.2308\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.1494 - categorical_accuracy: 0.1765 - val_loss: 1.9287 - val_categorical_accuracy: 0.2308\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.2339 - categorical_accuracy: 0.0980 - val_loss: 1.9290 - val_categorical_accuracy: 0.2308\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.2939 - categorical_accuracy: 0.0784 - val_loss: 1.9293 - val_categorical_accuracy: 0.2308\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.2585 - categorical_accuracy: 0.1373 - val_loss: 1.9296 - val_categorical_accuracy: 0.2308\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.2062 - categorical_accuracy: 0.1765 - val_loss: 1.9300 - val_categorical_accuracy: 0.2308\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.2108 - categorical_accuracy: 0.2549 - val_loss: 1.9303 - val_categorical_accuracy: 0.2308\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.2478 - categorical_accuracy: 0.1765 - val_loss: 1.9307 - val_categorical_accuracy: 0.2308\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.2032 - categorical_accuracy: 0.1961 - val_loss: 1.9311 - val_categorical_accuracy: 0.2308\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.0282 - categorical_accuracy: 0.1176 - val_loss: 1.9316 - val_categorical_accuracy: 0.2308\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.7985 - categorical_accuracy: 0.1569 - val_loss: 1.9320 - val_categorical_accuracy: 0.2308\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.3395 - categorical_accuracy: 0.1176 - val_loss: 1.9325 - val_categorical_accuracy: 0.2308\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0860 - categorical_accuracy: 0.1961 - val_loss: 1.9331 - val_categorical_accuracy: 0.2308\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0853 - categorical_accuracy: 0.1569 - val_loss: 1.9336 - val_categorical_accuracy: 0.2308\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.3243 - categorical_accuracy: 0.0784 - val_loss: 1.9342 - val_categorical_accuracy: 0.2308\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.2074 - categorical_accuracy: 0.2157 - val_loss: 1.9347 - val_categorical_accuracy: 0.2308\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.2320 - categorical_accuracy: 0.1569 - val_loss: 1.9352 - val_categorical_accuracy: 0.2308\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.1857 - categorical_accuracy: 0.1176 - val_loss: 1.9358 - val_categorical_accuracy: 0.2308\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.1262 - categorical_accuracy: 0.2157 - val_loss: 1.9364 - val_categorical_accuracy: 0.2308\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.1501 - categorical_accuracy: 0.1373 - val_loss: 1.9370 - val_categorical_accuracy: 0.2308\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.2892 - categorical_accuracy: 0.1569 - val_loss: 1.9376 - val_categorical_accuracy: 0.2308\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.1954 - categorical_accuracy: 0.1373 - val_loss: 1.9382 - val_categorical_accuracy: 0.2308\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.1883 - categorical_accuracy: 0.2157 - val_loss: 1.9389 - val_categorical_accuracy: 0.2308\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0888 - categorical_accuracy: 0.1765 - val_loss: 1.9396 - val_categorical_accuracy: 0.2308\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1147 - categorical_accuracy: 0.2157 - val_loss: 1.9403 - val_categorical_accuracy: 0.2308\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.2464 - categorical_accuracy: 0.1765 - val_loss: 1.9410 - val_categorical_accuracy: 0.2308\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.2496 - categorical_accuracy: 0.1765 - val_loss: 1.9417 - val_categorical_accuracy: 0.2308\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.2417 - categorical_accuracy: 0.1765 - val_loss: 1.9425 - val_categorical_accuracy: 0.2308\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1248 - categorical_accuracy: 0.1569 - val_loss: 1.9433 - val_categorical_accuracy: 0.2308\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.4003 - categorical_accuracy: 0.1961 - val_loss: 1.9441 - val_categorical_accuracy: 0.2308\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.2593 - categorical_accuracy: 0.1569 - val_loss: 1.9449 - val_categorical_accuracy: 0.2308\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0320 - categorical_accuracy: 0.1961 - val_loss: 1.9457 - val_categorical_accuracy: 0.2308\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.2739 - categorical_accuracy: 0.1765 - val_loss: 1.9465 - val_categorical_accuracy: 0.2308\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.8597 - categorical_accuracy: 0.2353 - val_loss: 1.9473 - val_categorical_accuracy: 0.2308\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.2042 - categorical_accuracy: 0.1373 - val_loss: 1.9481 - val_categorical_accuracy: 0.2308\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.1387 - categorical_accuracy: 0.1961 - val_loss: 1.9488 - val_categorical_accuracy: 0.3077\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0959 - categorical_accuracy: 0.1373 - val_loss: 1.9496 - val_categorical_accuracy: 0.3077\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.8951 - categorical_accuracy: 0.1569 - val_loss: 1.9504 - val_categorical_accuracy: 0.3077\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.2055 - categorical_accuracy: 0.1373 - val_loss: 1.9512 - val_categorical_accuracy: 0.3077\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.2071 - categorical_accuracy: 0.0980 - val_loss: 1.9520 - val_categorical_accuracy: 0.3077\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.9126 - categorical_accuracy: 0.1961 - val_loss: 1.9528 - val_categorical_accuracy: 0.3077\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.4275 - categorical_accuracy: 0.1569 - val_loss: 1.9536 - val_categorical_accuracy: 0.3077\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.1145 - categorical_accuracy: 0.1961 - val_loss: 1.9544 - val_categorical_accuracy: 0.3077\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0178 - categorical_accuracy: 0.1569 - val_loss: 1.9552 - val_categorical_accuracy: 0.3077\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.1836 - categorical_accuracy: 0.1961 - val_loss: 1.9560 - val_categorical_accuracy: 0.3077\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.9884 - categorical_accuracy: 0.1961 - val_loss: 1.9569 - val_categorical_accuracy: 0.3077\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.4253 - categorical_accuracy: 0.1765 - val_loss: 1.9577 - val_categorical_accuracy: 0.3077\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0443 - categorical_accuracy: 0.1961 - val_loss: 1.9585 - val_categorical_accuracy: 0.3077\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.1292 - categorical_accuracy: 0.1765 - val_loss: 1.9593 - val_categorical_accuracy: 0.3077\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.1506 - categorical_accuracy: 0.1765 - val_loss: 1.9601 - val_categorical_accuracy: 0.3077\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0940 - categorical_accuracy: 0.2353 - val_loss: 1.9609 - val_categorical_accuracy: 0.3077\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.8707 - categorical_accuracy: 0.1961 - val_loss: 1.9617 - val_categorical_accuracy: 0.3077\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1017 - categorical_accuracy: 0.1961 - val_loss: 1.9625 - val_categorical_accuracy: 0.3077\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.2323 - categorical_accuracy: 0.1961 - val_loss: 1.9633 - val_categorical_accuracy: 0.3077\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.1874 - categorical_accuracy: 0.1373 - val_loss: 1.9641 - val_categorical_accuracy: 0.3077\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.1650 - categorical_accuracy: 0.1961 - val_loss: 1.9649 - val_categorical_accuracy: 0.3077\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.2700 - categorical_accuracy: 0.1569 - val_loss: 1.9656 - val_categorical_accuracy: 0.3077\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.3849 - categorical_accuracy: 0.1176 - val_loss: 1.9664 - val_categorical_accuracy: 0.3077\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.8942 - categorical_accuracy: 0.2941 - val_loss: 1.9672 - val_categorical_accuracy: 0.3077\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1654 - categorical_accuracy: 0.1373 - val_loss: 1.9679 - val_categorical_accuracy: 0.3077\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.1308 - categorical_accuracy: 0.2157 - val_loss: 1.9686 - val_categorical_accuracy: 0.3077\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.2860 - categorical_accuracy: 0.1176 - val_loss: 1.9694 - val_categorical_accuracy: 0.3077\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.1179 - categorical_accuracy: 0.1569 - val_loss: 1.9701 - val_categorical_accuracy: 0.3077\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.2713 - categorical_accuracy: 0.1373 - val_loss: 1.9708 - val_categorical_accuracy: 0.3077\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.2126 - categorical_accuracy: 0.1961 - val_loss: 1.9715 - val_categorical_accuracy: 0.2308\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.2872 - categorical_accuracy: 0.1569 - val_loss: 1.9722 - val_categorical_accuracy: 0.2308\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.4243 - categorical_accuracy: 0.1176 - val_loss: 1.9729 - val_categorical_accuracy: 0.2308\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.2135 - categorical_accuracy: 0.1373 - val_loss: 1.9736 - val_categorical_accuracy: 0.2308\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.3349 - categorical_accuracy: 0.0784 - val_loss: 1.9743 - val_categorical_accuracy: 0.2308\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.9314 - categorical_accuracy: 0.1569 - val_loss: 1.9750 - val_categorical_accuracy: 0.2308\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0775 - categorical_accuracy: 0.1961 - val_loss: 1.9757 - val_categorical_accuracy: 0.2308\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0376 - categorical_accuracy: 0.1176 - val_loss: 1.9764 - val_categorical_accuracy: 0.2308\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.2408 - categorical_accuracy: 0.1765 - val_loss: 1.9771 - val_categorical_accuracy: 0.2308\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0963 - categorical_accuracy: 0.1569 - val_loss: 1.9777 - val_categorical_accuracy: 0.2308\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0239 - categorical_accuracy: 0.1569 - val_loss: 1.9784 - val_categorical_accuracy: 0.2308\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.0386 - categorical_accuracy: 0.2549 - val_loss: 1.9790 - val_categorical_accuracy: 0.2308\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0978 - categorical_accuracy: 0.1961 - val_loss: 1.9797 - val_categorical_accuracy: 0.2308\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.3020 - categorical_accuracy: 0.1765 - val_loss: 1.9803 - val_categorical_accuracy: 0.2308\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.1518 - categorical_accuracy: 0.2353 - val_loss: 1.9809 - val_categorical_accuracy: 0.2308\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1709 - categorical_accuracy: 0.1373 - val_loss: 1.9815 - val_categorical_accuracy: 0.2308\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.2293 - categorical_accuracy: 0.1765 - val_loss: 1.9822 - val_categorical_accuracy: 0.2308\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.9599 - categorical_accuracy: 0.1961 - val_loss: 1.9827 - val_categorical_accuracy: 0.2308\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.2044 - categorical_accuracy: 0.1373 - val_loss: 1.9833 - val_categorical_accuracy: 0.2308\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.1140 - categorical_accuracy: 0.2157 - val_loss: 1.9839 - val_categorical_accuracy: 0.2308\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.3456 - categorical_accuracy: 0.1765 - val_loss: 1.9845 - val_categorical_accuracy: 0.2308\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.2875 - categorical_accuracy: 0.1765 - val_loss: 1.9851 - val_categorical_accuracy: 0.2308\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.2441 - categorical_accuracy: 0.1961 - val_loss: 1.9856 - val_categorical_accuracy: 0.2308\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1144 - categorical_accuracy: 0.1176 - val_loss: 1.9862 - val_categorical_accuracy: 0.2308\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.1095 - categorical_accuracy: 0.1765 - val_loss: 1.9868 - val_categorical_accuracy: 0.2308\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.1058 - categorical_accuracy: 0.2157 - val_loss: 1.9874 - val_categorical_accuracy: 0.2308\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.2152 - categorical_accuracy: 0.1961 - val_loss: 1.9880 - val_categorical_accuracy: 0.2308\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.0069 - categorical_accuracy: 0.1961 - val_loss: 1.9886 - val_categorical_accuracy: 0.2308\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0295 - categorical_accuracy: 0.2157 - val_loss: 1.9892 - val_categorical_accuracy: 0.2308\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.9955 - categorical_accuracy: 0.1765 - val_loss: 1.9897 - val_categorical_accuracy: 0.2308\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.1514 - categorical_accuracy: 0.1176 - val_loss: 1.9903 - val_categorical_accuracy: 0.2308\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.2161 - categorical_accuracy: 0.1961 - val_loss: 1.9908 - val_categorical_accuracy: 0.2308\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.1245 - categorical_accuracy: 0.1373 - val_loss: 1.9913 - val_categorical_accuracy: 0.2308\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0093 - categorical_accuracy: 0.1961 - val_loss: 1.9919 - val_categorical_accuracy: 0.2308\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0606 - categorical_accuracy: 0.1961 - val_loss: 1.9924 - val_categorical_accuracy: 0.2308\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.2590 - categorical_accuracy: 0.1569 - val_loss: 1.9929 - val_categorical_accuracy: 0.2308\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.1432 - categorical_accuracy: 0.1765 - val_loss: 1.9935 - val_categorical_accuracy: 0.2308\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.9860 - categorical_accuracy: 0.1569 - val_loss: 1.9940 - val_categorical_accuracy: 0.2308\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.9865 - categorical_accuracy: 0.2549 - val_loss: 1.9946 - val_categorical_accuracy: 0.2308\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.1335 - categorical_accuracy: 0.1176 - val_loss: 1.9952 - val_categorical_accuracy: 0.2308\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1127 - categorical_accuracy: 0.1961 - val_loss: 1.9957 - val_categorical_accuracy: 0.2308\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.9567 - categorical_accuracy: 0.1765 - val_loss: 1.9963 - val_categorical_accuracy: 0.2308\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1208 - categorical_accuracy: 0.2353 - val_loss: 1.9968 - val_categorical_accuracy: 0.2308\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.1902 - categorical_accuracy: 0.1569 - val_loss: 1.9974 - val_categorical_accuracy: 0.2308\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0400 - categorical_accuracy: 0.2157 - val_loss: 1.9979 - val_categorical_accuracy: 0.2308\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.1427 - categorical_accuracy: 0.1176 - val_loss: 1.9985 - val_categorical_accuracy: 0.2308\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.2816 - categorical_accuracy: 0.1961 - val_loss: 1.9990 - val_categorical_accuracy: 0.2308\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.1482 - categorical_accuracy: 0.1569 - val_loss: 1.9996 - val_categorical_accuracy: 0.2308\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.2164 - categorical_accuracy: 0.1765 - val_loss: 2.0001 - val_categorical_accuracy: 0.2308\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.9944 - categorical_accuracy: 0.2549 - val_loss: 2.0006 - val_categorical_accuracy: 0.2308\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.1748 - categorical_accuracy: 0.1569 - val_loss: 2.0012 - val_categorical_accuracy: 0.2308\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.0363 - categorical_accuracy: 0.1961 - val_loss: 2.0017 - val_categorical_accuracy: 0.2308\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.2403 - categorical_accuracy: 0.1765 - val_loss: 2.0022 - val_categorical_accuracy: 0.2308\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.1048 - categorical_accuracy: 0.1961 - val_loss: 2.0027 - val_categorical_accuracy: 0.2308\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0646 - categorical_accuracy: 0.1765 - val_loss: 2.0032 - val_categorical_accuracy: 0.2308\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.2831 - categorical_accuracy: 0.1765 - val_loss: 2.0037 - val_categorical_accuracy: 0.2308\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.9670 - categorical_accuracy: 0.1176 - val_loss: 2.0041 - val_categorical_accuracy: 0.2308\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.0413 - categorical_accuracy: 0.2353 - val_loss: 2.0046 - val_categorical_accuracy: 0.2308\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.1390 - categorical_accuracy: 0.1765 - val_loss: 2.0051 - val_categorical_accuracy: 0.2308\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1929 - categorical_accuracy: 0.2353 - val_loss: 2.0056 - val_categorical_accuracy: 0.2308\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.1679 - categorical_accuracy: 0.1373 - val_loss: 2.0061 - val_categorical_accuracy: 0.2308\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.2461 - categorical_accuracy: 0.1961 - val_loss: 2.0065 - val_categorical_accuracy: 0.2308\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.0244 - categorical_accuracy: 0.1961 - val_loss: 2.0070 - val_categorical_accuracy: 0.2308\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.3436 - categorical_accuracy: 0.1569 - val_loss: 2.0075 - val_categorical_accuracy: 0.2308\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.1708 - categorical_accuracy: 0.1961 - val_loss: 2.0080 - val_categorical_accuracy: 0.2308\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.2691 - categorical_accuracy: 0.1961 - val_loss: 2.0085 - val_categorical_accuracy: 0.2308\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.1833 - categorical_accuracy: 0.1373 - val_loss: 2.0090 - val_categorical_accuracy: 0.2308\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0249 - categorical_accuracy: 0.1765 - val_loss: 2.0094 - val_categorical_accuracy: 0.2308\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.0960 - categorical_accuracy: 0.1569 - val_loss: 2.0099 - val_categorical_accuracy: 0.2308\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.1347 - categorical_accuracy: 0.1765 - val_loss: 2.0104 - val_categorical_accuracy: 0.2308\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.3247 - categorical_accuracy: 0.1961 - val_loss: 2.0108 - val_categorical_accuracy: 0.2308\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.2241 - categorical_accuracy: 0.1569 - val_loss: 2.0112 - val_categorical_accuracy: 0.2308\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0531 - categorical_accuracy: 0.2157 - val_loss: 2.0117 - val_categorical_accuracy: 0.2308\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0914 - categorical_accuracy: 0.1373 - val_loss: 2.0121 - val_categorical_accuracy: 0.2308\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.1881 - categorical_accuracy: 0.1569 - val_loss: 2.0126 - val_categorical_accuracy: 0.2308\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.1898 - categorical_accuracy: 0.1373 - val_loss: 2.0130 - val_categorical_accuracy: 0.2308\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.1652 - categorical_accuracy: 0.1569 - val_loss: 2.0134 - val_categorical_accuracy: 0.2308\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.2751 - categorical_accuracy: 0.1765 - val_loss: 2.0139 - val_categorical_accuracy: 0.2308\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.1579 - categorical_accuracy: 0.1569 - val_loss: 2.0143 - val_categorical_accuracy: 0.2308\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.2176 - categorical_accuracy: 0.1569 - val_loss: 2.0147 - val_categorical_accuracy: 0.2308\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.9809 - categorical_accuracy: 0.1569 - val_loss: 2.0151 - val_categorical_accuracy: 0.2308\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0484 - categorical_accuracy: 0.1961 - val_loss: 2.0154 - val_categorical_accuracy: 0.2308\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.2308 - categorical_accuracy: 0.1961 - val_loss: 2.0158 - val_categorical_accuracy: 0.2308\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0375 - categorical_accuracy: 0.2157 - val_loss: 2.0162 - val_categorical_accuracy: 0.2308\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.2689 - categorical_accuracy: 0.1176 - val_loss: 2.0165 - val_categorical_accuracy: 0.2308\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.9825 - categorical_accuracy: 0.1569 - val_loss: 2.0169 - val_categorical_accuracy: 0.2308\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1007 - categorical_accuracy: 0.1961 - val_loss: 2.0172 - val_categorical_accuracy: 0.2308\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.8669 - categorical_accuracy: 0.1569 - val_loss: 2.0175 - val_categorical_accuracy: 0.2308\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0135 - categorical_accuracy: 0.2157 - val_loss: 2.0178 - val_categorical_accuracy: 0.2308\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.9793 - categorical_accuracy: 0.1961 - val_loss: 2.0181 - val_categorical_accuracy: 0.2308\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0506 - categorical_accuracy: 0.1961 - val_loss: 2.0184 - val_categorical_accuracy: 0.2308\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0656 - categorical_accuracy: 0.1765 - val_loss: 2.0187 - val_categorical_accuracy: 0.2308\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.1639 - categorical_accuracy: 0.1569 - val_loss: 2.0189 - val_categorical_accuracy: 0.2308\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.9884 - categorical_accuracy: 0.1961 - val_loss: 2.0191 - val_categorical_accuracy: 0.2308\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.8552 - categorical_accuracy: 0.1176 - val_loss: 2.0194 - val_categorical_accuracy: 0.2308\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0298 - categorical_accuracy: 0.1569 - val_loss: 2.0196 - val_categorical_accuracy: 0.2308\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.3165 - categorical_accuracy: 0.1176 - val_loss: 2.0198 - val_categorical_accuracy: 0.2308\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.9606 - categorical_accuracy: 0.2157 - val_loss: 2.0200 - val_categorical_accuracy: 0.2308\n",
      "Epoch 214/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[84], line 71\u001B[0m\n\u001B[1;32m     68\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mSGD(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.000001\u001B[39m, decay \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1e-6\u001B[39m), loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     70\u001B[0m \u001B[38;5;66;03m# Train the model using the generator\u001B[39;00m\n\u001B[0;32m---> 71\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m plot_training_history(model\u001B[38;5;241m.\u001B[39mhistory)\n\u001B[1;32m     75\u001B[0m \u001B[38;5;66;03m# Calculate and print the total time taken for training\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/keras/src/engine/training.py:1789\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1787\u001B[0m logs \u001B[38;5;241m=\u001B[39m tmp_logs\n\u001B[1;32m   1788\u001B[0m end_step \u001B[38;5;241m=\u001B[39m step \u001B[38;5;241m+\u001B[39m data_handler\u001B[38;5;241m.\u001B[39mstep_increment\n\u001B[0;32m-> 1789\u001B[0m \u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_train_batch_end\u001B[49m\u001B[43m(\u001B[49m\u001B[43mend_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1790\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n\u001B[1;32m   1791\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/keras/src/callbacks.py:475\u001B[0m, in \u001B[0;36mCallbackList.on_train_batch_end\u001B[0;34m(self, batch, logs)\u001B[0m\n\u001B[1;32m    468\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001B[39;00m\n\u001B[1;32m    469\u001B[0m \n\u001B[1;32m    470\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m    471\u001B[0m \u001B[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001B[39;00m\n\u001B[1;32m    472\u001B[0m \u001B[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001B[39;00m\n\u001B[1;32m    473\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    474\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_call_train_batch_hooks:\n\u001B[0;32m--> 475\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mModeKeys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTRAIN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mend\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/keras/src/callbacks.py:322\u001B[0m, in \u001B[0;36mCallbackList._call_batch_hook\u001B[0;34m(self, mode, hook, batch, logs)\u001B[0m\n\u001B[1;32m    320\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_batch_begin_hook(mode, batch, logs)\n\u001B[1;32m    321\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m hook \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 322\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_end_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    323\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    324\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    325\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized hook: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    326\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected values are [\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbegin\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    327\u001B[0m     )\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/keras/src/callbacks.py:345\u001B[0m, in \u001B[0;36mCallbackList._call_batch_end_hook\u001B[0;34m(self, mode, batch, logs)\u001B[0m\n\u001B[1;32m    342\u001B[0m     batch_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_start_time\n\u001B[1;32m    343\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_times\u001B[38;5;241m.\u001B[39mappend(batch_time)\n\u001B[0;32m--> 345\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_hook_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhook_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_times) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_batches_for_timing_check:\n\u001B[1;32m    348\u001B[0m     end_hook_name \u001B[38;5;241m=\u001B[39m hook_name\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/keras/src/callbacks.py:393\u001B[0m, in \u001B[0;36mCallbackList._call_batch_hook_helper\u001B[0;34m(self, hook_name, batch, logs)\u001B[0m\n\u001B[1;32m    391\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks:\n\u001B[1;32m    392\u001B[0m     hook \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(callback, hook_name)\n\u001B[0;32m--> 393\u001B[0m     \u001B[43mhook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    395\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_timing:\n\u001B[1;32m    396\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m hook_name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_hook_times:\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/keras/src/callbacks.py:1093\u001B[0m, in \u001B[0;36mProgbarLogger.on_train_batch_end\u001B[0;34m(self, batch, logs)\u001B[0m\n\u001B[1;32m   1092\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mon_train_batch_end\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch, logs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m-> 1093\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_batch_update_progbar\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/keras/src/callbacks.py:1169\u001B[0m, in \u001B[0;36mProgbarLogger._batch_update_progbar\u001B[0;34m(self, batch, logs)\u001B[0m\n\u001B[1;32m   1165\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseen \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m add_seen\n\u001B[1;32m   1167\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   1168\u001B[0m     \u001B[38;5;66;03m# Only block async when verbose = 1.\u001B[39;00m\n\u001B[0;32m-> 1169\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[43mtf_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msync_to_numpy_or_python_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1170\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprogbar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseen, \u001B[38;5;28mlist\u001B[39m(logs\u001B[38;5;241m.\u001B[39mitems()), finalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/keras/src/utils/tf_utils.py:694\u001B[0m, in \u001B[0;36msync_to_numpy_or_python_type\u001B[0;34m(tensors)\u001B[0m\n\u001B[1;32m    691\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\n\u001B[1;32m    692\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mndim(t) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[0;32m--> 694\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_structure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_to_single_numpy_or_python_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/tensorflow/python/util/nest.py:629\u001B[0m, in \u001B[0;36mmap_structure\u001B[0;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[1;32m    543\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnest.map_structure\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    544\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmap_structure\u001B[39m(func, \u001B[38;5;241m*\u001B[39mstructure, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    545\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001B[39;00m\n\u001B[1;32m    546\u001B[0m \n\u001B[1;32m    547\u001B[0m \u001B[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001B[39;00m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 629\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnest_util\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_structure\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    630\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnest_util\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mModality\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCORE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mstructure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1168\u001B[0m, in \u001B[0;36mmap_structure\u001B[0;34m(modality, func, *structure, **kwargs)\u001B[0m\n\u001B[1;32m   1071\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001B[39;00m\n\u001B[1;32m   1072\u001B[0m \n\u001B[1;32m   1073\u001B[0m \u001B[38;5;124;03m- For Modality.CORE: Refer to\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1165\u001B[0m \u001B[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001B[39;00m\n\u001B[1;32m   1166\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1167\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m modality \u001B[38;5;241m==\u001B[39m Modality\u001B[38;5;241m.\u001B[39mCORE:\n\u001B[0;32m-> 1168\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_tf_core_map_structure\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mstructure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1169\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m modality \u001B[38;5;241m==\u001B[39m Modality\u001B[38;5;241m.\u001B[39mDATA:\n\u001B[1;32m   1170\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _tf_data_map_structure(func, \u001B[38;5;241m*\u001B[39mstructure, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1208\u001B[0m, in \u001B[0;36m_tf_core_map_structure\u001B[0;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[1;32m   1203\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (_tf_core_flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[1;32m   1204\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[1;32m   1206\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _tf_core_pack_sequence_as(\n\u001B[1;32m   1207\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m-> 1208\u001B[0m     \u001B[43m[\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mentries\u001B[49m\u001B[43m]\u001B[49m,\n\u001B[1;32m   1209\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites,\n\u001B[1;32m   1210\u001B[0m )\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1208\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1203\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (_tf_core_flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[1;32m   1204\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[1;32m   1206\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _tf_core_pack_sequence_as(\n\u001B[1;32m   1207\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m-> 1208\u001B[0m     [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[1;32m   1209\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites,\n\u001B[1;32m   1210\u001B[0m )\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/keras/src/utils/tf_utils.py:687\u001B[0m, in \u001B[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m    684\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_to_single_numpy_or_python_type\u001B[39m(t):\n\u001B[1;32m    685\u001B[0m     \u001B[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001B[39;00m\n\u001B[1;32m    686\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, tf\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[0;32m--> 687\u001B[0m         t \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    688\u001B[0m     \u001B[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001B[39;00m\n\u001B[1;32m    689\u001B[0m     \u001B[38;5;66;03m# as-is.\u001B[39;00m\n\u001B[1;32m    690\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, (np\u001B[38;5;241m.\u001B[39mndarray, np\u001B[38;5;241m.\u001B[39mgeneric)):\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:396\u001B[0m, in \u001B[0;36m_EagerTensorBase.numpy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    373\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001B[39;00m\n\u001B[1;32m    374\u001B[0m \n\u001B[1;32m    375\u001B[0m \u001B[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    393\u001B[0m \u001B[38;5;124;03m    NumPy dtype.\u001B[39;00m\n\u001B[1;32m    394\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    395\u001B[0m \u001B[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001B[39;00m\n\u001B[0;32m--> 396\u001B[0m maybe_arr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    397\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m maybe_arr\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(maybe_arr, np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;28;01melse\u001B[39;00m maybe_arr\n",
      "File \u001B[0;32m~/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:362\u001B[0m, in \u001B[0;36m_EagerTensorBase._numpy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    360\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_numpy\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    361\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 362\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_numpy_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    363\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    364\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers.legacy import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Set your data directory\n",
    "data_directory = '/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/data/train'  # Update this path to the directory containing your dataset\n",
    "\n",
    "# Define constants\n",
    "input_shape = (48, 48, 1)  # Input size for VGGNet\n",
    "num_classes = 7  # Automatically determine the number of classes\n",
    "batch_size = 64\n",
    "epochs = 500\n",
    "\n",
    "# Load and preprocess the data using your existing code\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen_with_preprocessing = datagen.flow_from_directory(\n",
    "    data_directory,\n",
    "    target_size=(48, 48),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X, y = datagen_with_preprocessing.next()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Define a custom CNN model\n",
    "model = Sequential()\n",
    "# Add convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add fully connected layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=SGD(learning_rate=0.000001, decay = 1e-6), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Train the model using the generator\n",
    "model.fit(X_train, y_train, len(X_train), epochs=epochs, validation_data=(X_val, y_val))\n",
    "\n",
    "plot_training_history(model.history)\n",
    "\n",
    "# Calculate and print the total time taken for training\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Total training time: {training_time} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T04:58:59.328023Z",
     "start_time": "2023-10-17T04:58:46.648521Z"
    }
   },
   "id": "27d42b82257782cb"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 895ms/step - loss: 4.3228 - categorical_accuracy: 0.2256 - val_loss: 3.4247 - val_categorical_accuracy: 0.0015\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 1s 636ms/step - loss: 3.9393 - categorical_accuracy: 0.2889 - val_loss: 3.4154 - val_categorical_accuracy: 0.0015\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 3.5725 - categorical_accuracy: 0.3687 - val_loss: 3.4070 - val_categorical_accuracy: 0.0015\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 3.3085 - categorical_accuracy: 0.4324 - val_loss: 3.3990 - val_categorical_accuracy: 0.0015\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 3.0783 - categorical_accuracy: 0.5046 - val_loss: 3.3913 - val_categorical_accuracy: 0.0046\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 2.8723 - categorical_accuracy: 0.5588 - val_loss: 3.3839 - val_categorical_accuracy: 0.0061\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 2.7486 - categorical_accuracy: 0.6027 - val_loss: 3.3764 - val_categorical_accuracy: 0.0152\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 2.6501 - categorical_accuracy: 0.6416 - val_loss: 3.3691 - val_categorical_accuracy: 0.0198\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 2.5474 - categorical_accuracy: 0.6767 - val_loss: 3.3609 - val_categorical_accuracy: 0.0168\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 2.4618 - categorical_accuracy: 0.7053 - val_loss: 3.3519 - val_categorical_accuracy: 0.0198\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 2.4172 - categorical_accuracy: 0.7176 - val_loss: 3.3424 - val_categorical_accuracy: 0.0183\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 2.3417 - categorical_accuracy: 0.7427 - val_loss: 3.3313 - val_categorical_accuracy: 0.0244\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 2.3348 - categorical_accuracy: 0.7492 - val_loss: 3.3190 - val_categorical_accuracy: 0.0320\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 2.2977 - categorical_accuracy: 0.7622 - val_loss: 3.3051 - val_categorical_accuracy: 0.0503\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 2.2397 - categorical_accuracy: 0.7790 - val_loss: 3.2901 - val_categorical_accuracy: 0.0976\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 2.2073 - categorical_accuracy: 0.7802 - val_loss: 3.2740 - val_categorical_accuracy: 0.2149\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 2.1621 - categorical_accuracy: 0.7950 - val_loss: 3.2576 - val_categorical_accuracy: 0.3841\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 2.1801 - categorical_accuracy: 0.8000 - val_loss: 3.2415 - val_categorical_accuracy: 0.5793\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 2.1468 - categorical_accuracy: 0.8122 - val_loss: 3.2255 - val_categorical_accuracy: 0.7744\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 2.1338 - categorical_accuracy: 0.8099 - val_loss: 3.2101 - val_categorical_accuracy: 0.8552\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1200x400 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 21ms/step - loss: 3.2067 - categorical_accuracy: 0.8841\n",
      "Test Loss: 3.2067489624023438\n",
      "Test Accuracy: 0.8841463327407837\n",
      "Total training time: 8.532222032546997 seconds\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Set your data directory\n",
    "data_directory = '/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/data/train'  # Update this path to the directory containing your dataset\n",
    "\n",
    "# Define constants\n",
    "input_shape = (48, 48, 1)  # Input size for VGGNet\n",
    "num_classes = 7  # Automatically determine the number of classes\n",
    "batch_size = 4096\n",
    "epochs = 20\n",
    "\n",
    "# Load and preprocess the data using your existing code\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen_with_preprocessing = datagen.flow_from_directory(\n",
    "    data_directory,\n",
    "    target_size=(48, 48),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False,\n",
    ")\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X, y = datagen_with_preprocessing.next()\n",
    "X_t, X_test, y_t, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_t, y_t, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "# Add convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add fully connected layers with L2 regularization\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.01)))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001, decay = 1e-6), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Train the model using the generator\n",
    "model.fit(X_train, y_train, len(X_train), epochs=epochs, validation_data=(X_val, y_val))\n",
    "\n",
    "plot_training_history(model.history)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "model.save(\"CNN_shuffle_False.keras\")\n",
    "\n",
    "# Calculate and print the total time taken for training\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Total training time: {training_time} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T04:51:42.151208Z",
     "start_time": "2023-10-17T04:51:33.614484Z"
    }
   },
   "id": "8cf474de2e78b9e8"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 3.2054 - categorical_accuracy: 0.8633\n",
      "Test accuracy: 86.33%\n"
     ]
    }
   ],
   "source": [
    "test_data_directory = '/Users/shreyas/Desktop/5th_sem/DeepLearning_Lab/Project/training_experimental/data/test'\n",
    "\n",
    "# Define constants\n",
    "input_shape = (48, 48, 1)  # Update with the appropriate input shape\n",
    "batch_size = 1024  # Adjust the batch size if needed\n",
    "\n",
    "# Create an ImageDataGenerator for test data\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)  # You may need to adjust the preprocessing steps\n",
    "\n",
    "# Load and preprocess the test data\n",
    "test_data_generator = test_datagen.flow_from_directory(\n",
    "    test_data_directory,\n",
    "    target_size=(48, 48),\n",
    "    color_mode='grayscale',  # Update with the color mode used for your model\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Update according to your problem\n",
    "    shuffle=False  # Make sure shuffle is set to False for testing\n",
    ")\n",
    "\n",
    "X_test, y_test = test_data_generator.next()\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T04:51:56.101741Z",
     "start_time": "2023-10-17T04:51:55.372321Z"
    }
   },
   "id": "a05cf4bc2a694687"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T04:49:45.495786Z",
     "start_time": "2023-10-17T04:49:45.479581Z"
    }
   },
   "id": "ac0c6c8d12383b57"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
